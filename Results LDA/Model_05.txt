> # Discriminant analysis
> require(MASS)
> require(dplyr)
> require(ggplot2)
> # Data
> dados<-read.csv("G:/Meu Drive/Projeto/Resultados/Model_5.csv",header=TRUE)
> dados$Outcome<-as.factor(dados$Outcome)
> #dados[,-c(ncol(dados))] <- scale(dados[,-c(ncol(dados))])
> str(dados)
'data.frame':   138 obs. of  22 variables:
 $ dPs    : num  3.32 3.59 3.45 3.87 3.87 3.87 1.5 1.5 3.87 3.59 ...
 $ dHs    : num  4.61 3.47 3.69 3.06 3.06 3.06 4.7 4.7 3.06 3.47 ...
 $ dDs    : num  16.4 16.2 16.2 16.1 16.1 16.1 16 16 16.1 16.2 ...
 $ MVs    : num  789 926 931 941 941 941 906 906 941 926 ...
 $ dPg    : num  7.9 7.9 7.9 10.5 7.3 6.1 6.5 7.1 7.9 8.3 ...
 $ dHg    : num  12.4 12.4 12.4 16.6 13.7 12.4 14.1 8.6 12.4 12.5 ...
 $ dDg    : num  16.5 16.5 16.5 16.9 16.9 16.7 16 17.1 16.5 17 ...
 $ MWg    : num  329 329 329 146 174 202 476 460 329 408 ...
 $ MPg    : num  449 449 449 402 412 422 511 441 449 478 ...
 $ BPg    : num  774 774 774 582 612 639 937 886 774 810 ...
 $ FPg    : num  524 524 524 434 455 475 585 557 524 539 ...
 $ STg    : num  38.5 38.5 38.5 56.4 52.8 50 25.3 23.9 38.5 39.5 ...
 $ MVg    : num  318 318 318 122 155 188 239 238 318 333 ...
 $ Afg    : num  0.9 0.9 0.9 0.964 1.03 1.1 0.514 0.498 0.9 0.914 ...
 $ Dg     : num  0.996 0.996 0.996 1.18 1.11 1.07 0.995 0.966 0.996 1.18 ...
 $ CTg    : num  994 994 994 795 819 841 1180 1110 994 1040 ...
 $ CPg    : num  16.8 16.8 16.8 35.7 28.5 23.4 10.8 10.5 16.8 16.5 ...
 $ CVg    : num  1080 1080 1080 407 520 633 1650 1640 1080 1150 ...
 $ HFg    : num  46.3 46.3 46.3 25.7 31 36.3 84.3 76.6 46.3 51.3 ...
 $ G0g    : num  105 105 105 -680 -664 -648 -229 -70.1 105 120 ...
 $ H0g    : num  -359 -359 -359 -861 -903 -944 -933 -756 -359 -333 ...
 $ Outcome: Factor w/ 3 levels "G","I","S": 1 3 2 1 1 1 1 1 1 1 ...
> 
> # Data partition
> set.seed(555)
> proportion <- 0.995
> k <- nrow(dados)
> outs <- NULL
> 
> for (j in 1:k)
+ {
+ index <- sample(1:nrow(dados), round(proportion*nrow(dados)))
+ train <- dados[index, ]
+ test <- dados[-index, ]
+ 
+ 
+ lda.train <- lda(formula=Outcome~.,data=train,na.action="na.omit")
+ lda.train.p <- predict(lda.train,train)
+ 
+ # Confusion matrix and accuracy - testing data
+ p2 <- predict(lda.train, test)$class
+ tab1 <- table(Predicted = p2, Actual = test$Outcome)
+ outs[j] <- sum(diag(tab1))/sum(tab1)
+ }
> mean(outs)
[1] 0.8913043
> lda.train <- lda(formula=Outcome~.,data=dados,na.action="na.omit")
> lda.train
Call:
lda(Outcome ~ ., data = dados, na.action = "na.omit")

Prior probabilities of groups:
         G          I          S 
0.86956522 0.03623188 0.09420290 

Group means:
       dPs      dHs      dDs      MVs       dPg      dHg      dDg     MWg
G 4.167667 3.340000 16.09417 922.7750  6.675833 10.18500 16.73250 394.875
I 5.130000 5.054000 16.22000 949.4000 10.480000 16.28000 16.66000 419.600
S 4.096923 4.434615 16.23077 932.2308  7.553846 12.81538 16.65385 574.000
       MPg      BPg      FPg      STg      MVg      Afg        Dg      CTg
G 427.5000 780.1500 543.4583 34.42417 318.4750 1.002575 0.9650333 1013.783
I 472.8000 877.2000 576.0000 45.24000 268.8000 1.065200 1.0238000 1146.800
S 495.3846 940.3077 645.3846 38.81538 512.7692 1.221231 0.9920769 1383.385
       CPg      CVg      HFg       G0g       H0g
G 12.20117 1401.600 66.13583 -183.4657  -828.000
I 13.30200 1432.000 67.14000 -133.8000  -794.400
S 10.49846 2025.385 94.49231 -260.3846 -1243.385

Coefficients of linear discriminants:
              LD1          LD2
dPs  1.441648e-01 -0.451038457
dHs -9.612645e-02 -0.074169961
dDs  2.525830e+00  2.543472007
MVs  2.599364e-03 -0.009472864
dPg -6.329592e-02  0.166833957
dHg  1.651702e-01  0.115062499
dDg  9.934661e-01 -0.451563259
MWg  2.856526e-02 -0.036948428
MPg -1.465465e-02  0.022075100
BPg  1.406665e-02 -0.013318772
FPg -8.775992e-03 -0.022421118
STg  1.768457e-01 -0.216368590
MVg  1.030173e-02  0.002706423
Afg -3.911411e+00  3.458908612
Dg  -1.584227e+01 14.319393223
CTg  4.641193e-04  0.000855702
CPg  4.368689e-02  0.070528674
CVg -1.028440e-02  0.012047942
HFg  7.476927e-02 -0.054917332
G0g -2.509257e-03  0.007191502
H0g  3.469310e-03 -0.008000601

Proportion of trace:
   LD1    LD2 
0.7326 0.2674 
> lda.data <- cbind(dados, predict(lda.train)$x)
> ggplot(lda.data, aes(LD1, LD2)) +
+   geom_point(aes(color = Outcome))