> # Discriminant analysis
> require(MASS)
> require(dplyr)
> require(ggplot2)
> # Data
> dados<-read.csv("G:/Meu Drive/Projeto/Resultados/Model_15.csv",header=TRUE)
> dados$Outcome<-as.factor(dados$Outcome)
> #dados[,-c(ncol(dados))] <- scale(dados[,-c(ncol(dados))])
> str(dados)
'data.frame':   268 obs. of  12 variables:
 $ dPg    : num  12.8 12.4 7.9 13.3 13.9 14.9 13.2 12.4 13.3 13.9 ...
 $ dHg    : num  18.7 12.9 12.4 11.9 13.5 14.1 13.4 12.9 11.9 13.5 ...
 $ dDg    : num  16.6 17.7 16.5 17.2 17.2 17.1 18.9 17.7 17.2 17.2 ...
 $ dTg    : num  28.1 25.2 22.1 24.8 25.9 26.7 26.7 25.2 24.8 25.9 ...
 $ dPs    : num  3.44 1.5 3.45 1.5 1.5 1.5 1.5 4.1 4.1 4.1 ...
 $ dHs    : num  4.11 4.7 3.69 4.7 4.7 4.7 4.7 2.5 2.5 2.5 ...
 $ dDs    : num  16.2 16 16.2 16 16 16 16 16 16 16 ...
 $ dTs    : num  17.1 16.7 17 16.7 16.7 16.7 16.7 16.7 16.7 16.7 ...
 $ MVs    : num  952 906 931 906 906 906 906 947 947 947 ...
 $ Dist   : num  17.3 13.7 9.79 13.9 15.3 16.4 14.9 13.4 13.2 14.8 ...
 $ FH2    : num  346 209 119 179 229 251 227 64.2 55.9 71.1 ...
 $ Outcome: Factor w/ 3 levels "G","I","S": 3 1 2 1 1 1 1 1 1 1 ...
> 
> # Data partition
> set.seed(555)
> proportion <- 0.995
> k <- nrow(dados)
> outs <- NULL
> 
> for (j in 1:k)
+ {
+ index <- sample(1:nrow(dados), round(proportion*nrow(dados)))
+ train <- dados[index, ]
+ test <- dados[-index, ]
+ 
+ 
+ lda.train <- lda(formula=Outcome~.,data=train,na.action="na.omit")
+ lda.train.p <- predict(lda.train,train)
+ 
+ # Confusion matrix and accuracy - testing data
+ p2 <- predict(lda.train, test)$class
+ tab1 <- table(Predicted = p2, Actual = test$Outcome)
+ outs[j] <- sum(diag(tab1))/sum(tab1)
+ }
> mean(outs)
[1] 0.8507463
> lda.train <- lda(formula=Outcome~.,data=dados,na.action="na.omit")
> lda.train
Call:
lda(Outcome ~ ., data = dados, na.action = "na.omit")

Prior probabilities of groups:
         G          I          S 
0.86194030 0.03731343 0.10074627 

Group means:
       dPg       dHg      dDg      dTg      dPs      dHs      dDs      dTs
G 6.438797  9.310866 16.86450 20.84805 3.883939 3.395628 16.08658 16.95671
I 8.725000 12.291000 17.21000 23.71000 4.338000 4.842000 16.17000 17.59000
S 5.501481  9.639259 16.74074 20.77037 3.840000 4.115556 16.19259 17.22222
       MVs     Dist       FH2
G 925.1385 7.741039  85.20671
I 940.3000 9.648000 453.18300
S 939.2963 6.548519 170.51593

Coefficients of linear discriminants:
              LD1          LD2
dPg  -0.072845502 -0.179241791
dHg   0.106240733  0.274796806
dDg   0.310651547 -0.856903007
dTg   0.294184619  0.689726286
dPs  -0.054853589 -1.614412286
dHs   0.176228861 -1.747036282
dDs   0.568141022  0.040082912
dTs  -1.803097320  4.889661520
MVs   0.002023598  0.007954955
Dist -0.359931700 -0.578315162
FH2   0.006642522 -0.004611280

Proportion of trace:
   LD1    LD2 
0.6828 0.3172 
> lda.data <- cbind(dados, predict(lda.train)$x)
> ggplot(lda.data, aes(LD1, LD2)) +
+   geom_point(aes(color = Outcome), size=3)
> 
